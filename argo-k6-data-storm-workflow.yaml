apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: marklogic-data-storm-k6-
  namespace: ml
spec:
  entrypoint: marklogic-data-storm-pipeline
  serviceAccountName: argo-workflow
  
  arguments:
    parameters:
    - name: marklogic-host
      value: "ml-k6.ml-kube.com"
    - name: marklogic-port
      value: "443"
    - name: ssl-enabled
      value: "true"
    - name: insecure-skip-tls-verify
      value: "false"
    - name: base-path
      value: "/console"
    - name: database
      value: "Documents"
    - name: username
      value: "GeoAB"
    - name: password
      value: "X0FlWXIbvy"
    - name: auth-type
      value: "basic"
    - name: batch-size
      value: "100"
    - name: thread-count
      value: "8"
    - name: duration
      value: "5m"
  
  templates:
  - name: marklogic-data-storm-pipeline
    steps:
    - - name: deploy-test-config
        template: deploy-k6-config
    
    - - name: run-k6-test
        template: execute-k6-testrun
    
    - - name: wait-for-completion
        template: wait-test-completion
    
    - - name: get-test-results
        template: fetch-results
    
    - - name: cleanup
        template: cleanup-resources

  # Step 1: Deploy ConfigMap with k6 script
  - name: deploy-k6-config
    resource:
      action: apply
      manifest: |
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: marklogic-data-storm-script
          namespace: ml
        data:
          marklogic-data-storm.js: |
            import http from 'k6/http';
            import { check, sleep } from 'k6';
            import encoding from 'k6/encoding';
            import { Counter, Rate, Trend } from 'k6/metrics';

            // Custom metrics
            const documentsWritten = new Counter('documents_written');
            const writeErrors = new Rate('write_errors');
            const writeDuration = new Trend('write_duration');

            // Helper functions for random data generation
            function randomIntBetween(min, max) {
              return Math.floor(Math.random() * (max - min + 1)) + min;
            }

            function randomString(length) {
              const chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
              let result = '';
              for (let i = 0; i < length; i++) {
                result += chars.charAt(Math.floor(Math.random() * chars.length));
              }
              return result;
            }

            function randomEmail() {
              return `${randomString(8).toLowerCase()}@example.com`;
            }

            function randomIP() {
              return `${randomIntBetween(1, 255)}.${randomIntBetween(1, 255)}.${randomIntBetween(1, 255)}.${randomIntBetween(1, 255)}`;
            }

            function randomPhoneNumber() {
              return `${randomIntBetween(100, 999)}-${randomIntBetween(100, 999)}-${randomIntBetween(1000, 9999)}`;
            }

            function randomZipCode() {
              return `${randomIntBetween(10000, 99999)}`;
            }

            // Generate random document similar to marklogic-data-storm
            function generateRandomDocument() {
              return {
                first_name: randomString(8),
                last_name: randomString(10),
                email: randomEmail(),
                ip_address: randomIP(),
                city: randomString(10),
                state: randomString(2).toUpperCase(),
                postal_code: randomZipCode(),
                country: randomString(12),
                phone_number: randomPhoneNumber(),
                timestamp: new Date().toISOString()
              };
            }

            // Generate UUID for document URIs
            function generateUUID() {
              return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
                const r = Math.random() * 16 | 0;
                const v = c === 'x' ? r : (r & 0x3 | 0x8);
                return v.toString(16);
              });
            }

            // Test configuration - similar to marklogic-data-storm defaults
            export const options = {
              // Simulate thread count with VUs
              vus: parseInt(__ENV.THREAD_COUNT || '8'),
              duration: __ENV.DURATION || '5m',
              
              thresholds: {
                http_req_failed: ['rate<0.01'],     // Less than 1% errors
                http_req_duration: ['p(95)<3000'],  // 95% under 3s
                documents_written: ['count>0'],      // At least some documents written
                write_errors: ['rate<0.01'],         // Less than 1% write errors
              },
              
              // TLS/SSL configuration
              insecureSkipTLSVerify: __ENV.INSECURE_SKIP_TLS_VERIFY === 'true',
            };

            export default function () {
              // Configuration from environment variables (mimics properties file)
              const HOST = __ENV.HOST || 'ml-k6.ml-kube.com';
              const PORT = __ENV.PORT || '443';
              const SSL = __ENV.SSL !== 'false'; // Defaults to true (HTTPS), set to 'false' for HTTP
              const PROTOCOL = SSL ? 'https' : 'http';
              const DATABASE = __ENV.DATABASE || 'Documents';
              const USERNAME = __ENV.USERNAME || 'GeoAB';
              const PASSWORD = __ENV.PASSWORD || 'X0FlWXIbvy';
              const BASE_PATH = __ENV.BASE_PATH || '/console'; // Load balancer path for app server on port 8000
              const BATCH_SIZE = parseInt(__ENV.BATCH_SIZE || '100');
              const AUTH_TYPE = __ENV.AUTH_TYPE || 'basic'; // 'basic' or 'digest'
              const TRANSFORM = __ENV.REST_TRANSFORM || ''; // Optional REST transform
              const INSECURE_SKIP_TLS_VERIFY = __ENV.INSECURE_SKIP_TLS_VERIFY === 'true'; // Skip TLS verification
              
              // Build base URL
              const BASE_URL = `${PROTOCOL}://${HOST}:${PORT}${BASE_PATH}`;
              
              // Generate batch of documents (similar to marklogic-data-storm)
              const batch = [];
              for (let i = 0; i < BATCH_SIZE; i++) {
                const doc = generateRandomDocument();
                const uri = `/data-storm/row/${generateUUID()}.json`;
                batch.push({
                  uri: uri,
                  content: doc
                });
              }

              // Configure authentication
              const params = {
                headers: {
                  'Content-Type': 'application/json',
                },
                timeout: '30s',
                tags: { operation: 'bulk-write' },
              };

              // Add TLS skip verification if needed
              if (INSECURE_SKIP_TLS_VERIFY) {
                params.insecureSkipTLSVerify = true;
              }

              if (AUTH_TYPE === 'basic') {
                const credentials = `${USERNAME}:${PASSWORD}`;
                const encodedCredentials = encoding.b64encode(credentials);
                params.headers['Authorization'] = `Basic ${encodedCredentials}`;
              } else {
                // Digest authentication - k6 handles the challenge-response automatically
                params.auth = 'digest';
                params.username = USERNAME;
                params.password = PASSWORD;
              }

              // Record start time
              const startTime = new Date().getTime();
              
              let successCount = 0;
              let failCount = 0;

              // Write documents individually (MarkLogic REST API doesn't support JSON bulk format)
              // Use PUT for individual document writes
              for (let i = 0; i < batch.length; i++) {
                const item = batch[i];
                let writeUrl = `${BASE_URL}/v1/documents?uri=${encodeURIComponent(item.uri)}&database=${DATABASE}`;
                if (TRANSFORM) {
                  writeUrl += `&transform=${TRANSFORM}`;
                }
                
                const payload = JSON.stringify(item.content);
                const writeRes = http.put(writeUrl, payload, params);
                
                const writeSuccess = writeRes.status === 200 || writeRes.status === 201 || writeRes.status === 204;
                
                if (writeSuccess) {
                  successCount++;
                } else {
                  failCount++;
                  if (i === 0) { // Only log first error to avoid spam
                    console.error(`Write failed: ${writeRes.status} - ${writeRes.body}`);
                  }
                }
              }

              // Record metrics
              const duration = new Date().getTime() - startTime;
              writeDuration.add(duration);

              const overallSuccess = successCount > 0;
              
              check(overallSuccess, {
                'bulk write successful': () => overallSuccess,
                'write response time acceptable': () => duration < 30000,
              });

              documentsWritten.add(successCount);
              writeErrors.add(failCount);

              if (failCount > 0) {
                console.log(`Batch complete: ${successCount} succeeded, ${failCount} failed`);
              }

              // Sleep to simulate think time (adjustable)
              const thinkTime = parseFloat(__ENV.THINK_TIME || '0.1');
              sleep(thinkTime);
            }

            export function handleSummary(data) {
              const totalDocuments = data.metrics.documents_written.values.count || 0;
              const writeErrorRate = data.metrics.write_errors.values.rate || 0;
              const avgWriteDuration = data.metrics.write_duration.values.avg || 0;
              
              console.log('\n========================================');
              console.log('MarkLogic Data Storm Load Test Summary');
              console.log('========================================');
              console.log(`Total Documents Written: ${totalDocuments}`);
              console.log(`Write Error Rate: ${(writeErrorRate * 100).toFixed(2)}%`);
              console.log(`Average Write Duration: ${avgWriteDuration.toFixed(2)}ms`);
              console.log('========================================\n');

              return {
                'stdout': JSON.stringify(data, null, 2),
              };
            }

  # Step 2: Create k6 TestRun
  - name: execute-k6-testrun
    resource:
      action: apply
      manifest: |
        apiVersion: k6.io/v1alpha1
        kind: TestRun
        metadata:
          name: marklogic-data-storm-{{workflow.uid}}
          namespace: ml
        spec:
          parallelism: 1
          script:
            configMap:
              name: marklogic-data-storm-script
              file: marklogic-data-storm.js
          runner:
            image: grafana/k6:latest
            env:
            - name: HOST
              value: "{{workflow.parameters.marklogic-host}}"
            - name: PORT
              value: "{{workflow.parameters.marklogic-port}}"
            - name: SSL
              value: "{{workflow.parameters.ssl-enabled}}"
            - name: INSECURE_SKIP_TLS_VERIFY
              value: "{{workflow.parameters.insecure-skip-tls-verify}}"
            - name: BASE_PATH
              value: "{{workflow.parameters.base-path}}"
            - name: DATABASE
              value: "{{workflow.parameters.database}}"
            - name: USERNAME
              value: "{{workflow.parameters.username}}"
            - name: PASSWORD
              value: "{{workflow.parameters.password}}"
            - name: AUTH_TYPE
              value: "{{workflow.parameters.auth-type}}"
            - name: BATCH_SIZE
              value: "{{workflow.parameters.batch-size}}"
            - name: THREAD_COUNT
              value: "{{workflow.parameters.thread-count}}"
            - name: DURATION
              value: "{{workflow.parameters.duration}}"
            resources:
              requests:
                cpu: 500m
                memory: 512Mi
              limits:
                cpu: 1000m
                memory: 1Gi
          separate: false

  # Step 3: Wait for TestRun completion
  - name: wait-test-completion
    script:
      image: bitnami/kubectl:latest
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        TESTRUN_NAME="marklogic-data-storm-{{workflow.uid}}"
        NAMESPACE="ml"
        TIMEOUT=600
        ELAPSED=0
        
        echo "Waiting for TestRun ${TESTRUN_NAME} to complete..."
        
        while [ $ELAPSED -lt $TIMEOUT ]; do
          STATUS=$(kubectl get testrun ${TESTRUN_NAME} -n ${NAMESPACE} -o jsonpath='{.status.stage}' 2>/dev/null || echo "not-found")
          
          echo "Current status: ${STATUS}"
          
          if [ "$STATUS" == "finished" ] || [ "$STATUS" == "error" ]; then
            echo "TestRun completed with status: ${STATUS}"
            
            if [ "$STATUS" == "error" ]; then
              echo "TestRun failed!"
              exit 1
            fi
            
            exit 0
          fi
          
          sleep 10
          ELAPSED=$((ELAPSED + 10))
        done
        
        echo "Timeout waiting for TestRun to complete"
        exit 1

  # Step 4: Fetch test results
  - name: fetch-results
    script:
      image: bitnami/kubectl:latest
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        TESTRUN_NAME="marklogic-data-storm-{{workflow.uid}}"
        NAMESPACE="ml"
        
        echo "========================================="
        echo "K6 Data Storm Test Results"
        echo "========================================="
        
        # Get TestRun status
        echo ""
        echo "TestRun Status:"
        kubectl get testrun ${TESTRUN_NAME} -n ${NAMESPACE} -o yaml
        
        echo ""
        echo "========================================="
        echo "Test Logs:"
        echo "========================================="
        
        # Get logs from k6 pods
        kubectl logs -n ${NAMESPACE} -l k6_cr=${TESTRUN_NAME} --tail=500 || echo "No logs found"
        
        echo ""
        echo "========================================="
        echo "Test Summary Complete"
        echo "========================================="

  # Step 5: Cleanup resources
  - name: cleanup-resources
    script:
      image: bitnami/kubectl:latest
      command: [bash]
      source: |
        #!/bin/bash
        
        TESTRUN_NAME="marklogic-data-storm-{{workflow.uid}}"
        NAMESPACE="ml"
        
        echo "Cleaning up test resources..."
        
        # Delete TestRun (this will also delete associated pods)
        kubectl delete testrun ${TESTRUN_NAME} -n ${NAMESPACE} --ignore-not-found=true
        
        # Keep ConfigMap for reuse
        # kubectl delete configmap marklogic-data-storm-script -n ${NAMESPACE} --ignore-not-found=true
        
        echo "Cleanup complete"
